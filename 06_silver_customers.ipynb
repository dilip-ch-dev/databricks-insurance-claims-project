{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91116634-4d82-4959-b187-98d23314496c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Read Bronze customers and check schema\n",
    "bronze_customers = spark.table(\"smart_claims_dev.bronze.customers_raw\")\n",
    "\n",
    "print(f\"üìä Bronze Customers - Row Count: {bronze_customers.count():,}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç Schema:\")\n",
    "bronze_customers.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e049cdc-c239-4c81-8ca2-57182104b82b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Check for duplicates and basic statistics\n",
    "from pyspark.sql.functions import count, countDistinct\n",
    "\n",
    "# Get counts\n",
    "total_rows = bronze_customers.count()\n",
    "unique_customers = bronze_customers.select(countDistinct(\"customer_id\")).collect()[0][0]\n",
    "duplicate_count = total_rows - unique_customers\n",
    "\n",
    "# Display results\n",
    "print(f\"üìä BRONZE CUSTOMERS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Rows:              {total_rows:,}\")\n",
    "print(f\"Unique customer_id:      {unique_customers:,}\")\n",
    "print(f\"Duplicate Records:       {duplicate_count:,}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüîç SAMPLE DATA (First 5 rows):\")\n",
    "bronze_customers.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c2c226-ed73-4166-8b17-6dcf814d6217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Check for NULL values in critical columns\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Define critical columns that should NOT be null\n",
    "critical_columns = [\n",
    "    'customer_id',\n",
    "    'name',\n",
    "    'date_of_birth'\n",
    "]\n",
    "\n",
    "print(\"üîç NULL VALUE ANALYSIS - Critical Columns\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Column':<20} | {'Null Count':>12} | {'Null %':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check each column for nulls\n",
    "for column in critical_columns:\n",
    "    null_count = bronze_customers.filter(col(column).isNull()).count()\n",
    "    null_percentage = (null_count / total_rows) * 100\n",
    "    print(f\"{column:<20} | {null_count:>12,} | {null_percentage:>9.2f}%\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df1f4e7f-d019-48b9-af7a-d4c443760174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Date validation and age calculation (FINAL - with try_to_date)\n",
    "from pyspark.sql.functions import try_to_date, current_date, floor, datediff, when, col, lit, coalesce\n",
    "\n",
    "print(\"üîç DATE & AGE VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Try multiple date formats using try_to_date (returns NULL on failure, no error)\n",
    "customers_with_dates = bronze_customers.withColumn(\n",
    "    \"date_of_birth_parsed\",\n",
    "    when(col(\"date_of_birth\").isNull() | (col(\"date_of_birth\") == \"null\"), lit(None))\n",
    "    .otherwise(\n",
    "        coalesce(\n",
    "            try_to_date(col(\"date_of_birth\"), \"MM-dd-yyyy\"),  # Try US format\n",
    "            try_to_date(col(\"date_of_birth\"), \"dd-MM-yyyy\"),  # Try European format\n",
    "            try_to_date(col(\"date_of_birth\"), \"yyyy-MM-dd\")   # Try ISO format\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate age (only for valid dates)\n",
    "customers_with_age = customers_with_dates.withColumn(\n",
    "    \"age\",\n",
    "    when(col(\"date_of_birth_parsed\").isNotNull(),\n",
    "         floor(datediff(current_date(), col(\"date_of_birth_parsed\")) / 365.25)\n",
    "    ).otherwise(lit(None))\n",
    ")\n",
    "\n",
    "# Check 1: Invalid date formats (couldn't parse with any format)\n",
    "invalid_dates = customers_with_age.filter(col(\"date_of_birth_parsed\").isNull()).count()\n",
    "print(f\"‚ùå Invalid date formats:              {invalid_dates:>10,}\")\n",
    "\n",
    "# Check 2: Ages outside valid range (18-120)\n",
    "invalid_age = customers_with_age.filter(\n",
    "    col(\"age\").isNotNull() & ((col(\"age\") < 18) | (col(\"age\") > 120))\n",
    ").count()\n",
    "print(f\"‚ùå Invalid ages (<18 or >120):        {invalid_age:>10,}\")\n",
    "\n",
    "# Check 3: Future dates of birth\n",
    "future_dob = customers_with_age.filter(\n",
    "    col(\"date_of_birth_parsed\").isNotNull() & \n",
    "    (col(\"date_of_birth_parsed\") > current_date())\n",
    ").count()\n",
    "print(f\"‚ùå Future dates of birth:             {future_dob:>10,}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Summary\n",
    "total_invalid = invalid_dates + invalid_age + future_dob\n",
    "print(f\"\\nüìä TOTAL INVALID RECORDS: {total_invalid:,}\")\n",
    "print(f\"üìä VALID RECORDS: {total_rows - total_invalid:,} ({((total_rows - total_invalid)/total_rows)*100:.2f}%)\")\n",
    "\n",
    "# Show sample with age\n",
    "print(\"\\nüîç SAMPLE DATA WITH AGE (First 5 rows):\")\n",
    "customers_with_age.select(\"customer_id\", \"name\", \"date_of_birth\", \"date_of_birth_parsed\", \"age\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8793ebc-2ea8-465f-a30b-f1a5dbd22e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Transform Bronze to Silver - Apply all quality rules\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "print(\"üîß APPLYING TRANSFORMATIONS...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Start with parsed dates and ages\n",
    "customers_silver = customers_with_age\n",
    "\n",
    "# Filter 1: Remove customers with invalid dates (couldn't parse)\n",
    "customers_silver = customers_silver.filter(col(\"date_of_birth_parsed\").isNotNull())\n",
    "print(f\"‚úÖ Filter 1: Remove invalid date formats\")\n",
    "\n",
    "# Filter 2: Remove future dates of birth\n",
    "customers_silver = customers_silver.filter(col(\"date_of_birth_parsed\") <= current_date())\n",
    "print(f\"‚úÖ Filter 2: Remove future dates of birth\")\n",
    "\n",
    "# Filter 3: Remove invalid ages (< 18 or > 120)\n",
    "customers_silver = customers_silver.filter((col(\"age\") >= 18) & (col(\"age\") <= 120))\n",
    "print(f\"‚úÖ Filter 3: Remove invalid ages (<18 or >120)\")\n",
    "\n",
    "# Filter 4: Remove customers without names or IDs\n",
    "customers_silver = customers_silver.filter(\n",
    "    col(\"customer_id\").isNotNull() & \n",
    "    col(\"name\").isNotNull()\n",
    ")\n",
    "print(f\"‚úÖ Filter 4: Remove customers without ID or name\")\n",
    "\n",
    "# Add audit column: when was this record processed to Silver\n",
    "customers_silver = customers_silver.withColumn(\"processed_at\", current_timestamp())\n",
    "print(f\"‚úÖ Added audit column: processed_at\")\n",
    "\n",
    "# Drop temporary parsing column, keep age\n",
    "customers_silver = customers_silver.drop(\"date_of_birth_parsed\")\n",
    "print(f\"‚úÖ Dropped temporary column: date_of_birth_parsed\")\n",
    "\n",
    "# Show results\n",
    "final_count = customers_silver.count()\n",
    "removed_count = total_rows - final_count\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìä TRANSFORMATION RESULTS:\")\n",
    "print(f\"   Original Bronze rows:  {total_rows:>10,}\")\n",
    "print(f\"   Removed invalid rows:  {removed_count:>10,}\")\n",
    "print(f\"   Final Silver rows:     {final_count:>10,}\")\n",
    "print(f\"   Data quality:          {(final_count/total_rows)*100:>9.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "491ad65b-8b89-484f-8c0b-6ff572052227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Write cleaned customers to Silver Delta table\n",
    "print(\"üíæ WRITING TO SILVER LAYER...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Write to Delta table\n",
    "customers_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"smart_claims_dev.silver.customers_clean\")\n",
    "\n",
    "print(\"‚úÖ Successfully written to: smart_claims_dev.silver.customers_clean\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verify the write\n",
    "silver_table = spark.table(\"smart_claims_dev.silver.customers_clean\")\n",
    "silver_count = silver_table.count()\n",
    "\n",
    "print(f\"üîç VERIFICATION:\")\n",
    "print(f\"   Rows written:  {silver_count:>10,}\")\n",
    "print(f\"   Expected:      {final_count:>10,}\")\n",
    "print(f\"   Match:         {'‚úÖ YES' if silver_count == final_count else '‚ùå NO'}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show sample from Silver table\n",
    "print(\"\\nüìä SAMPLE SILVER DATA (First 5 rows):\")\n",
    "silver_table.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec8517a9-ba88-4750-a296-ec52129699e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Final summary - Bronze vs Silver comparison for customers\n",
    "print(\"=\" * 80)\n",
    "print(\"üéØ SILVER LAYER CUSTOMERS: FINAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Original Bronze Rows:         {total_rows:,}\")\n",
    "print(f\"Silver Rows (Cleaned):        {silver_count:,}\")\n",
    "print(f\"Data Quality Percent Pass:    {(silver_count/total_rows)*100:.2f}%\")\n",
    "print(\"=\" * 80)\n",
    "silver_table.printSchema()\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_silver_customers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
